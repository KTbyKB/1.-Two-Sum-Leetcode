#Frozen game - Q learning

import numpy as np
import gym
import random
import matplotlib.pyplot as plt
import pygame
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

env = gym.make('FrozenLake-v1',render_mode='human')
#Frozenlake environment as stochastic (True) or deterministic (False)

action_space_size = env.action_space.n
print('No of actions: ', action_space_size)

state_space_size = env.observation_space.n
print('No of states: ', state_space_size)

qtable = np.zeros((state_space_size, action_space_size))

episodes = 10000
alpha = 0.2 #learning rate
max_steps = 100
gamma = 0.99

epsilon = 1
decay_rate = 0.001
max_epsilon = 1
min_epsilon = 0.01

rewards = []
epsilon_values = []
avg_rewards = []
successes = []
ar = []
for episode in range(episodes):
    state = env.reset()[0]
    step = 0
    done = False
    total_reward = 0
    epi_reward = []
    for step in range(max_steps):
        if random.uniform(0,1) > epsilon:
            action = np.argmax(qtable[state,:])
        else:
            action = env.action_space.sample()
        new_state, reward, done, _, _ = env.step(action)
        max_new_state = np.max(qtable[new_state,:])
        
        #print(qtable[state,action])
        qtable[state,action] = qtable[state,action] + alpha*(reward + gamma*max_new_state - qtable[state,action])

        #print(qtable[state,action])
        total_reward += reward

        state = new_state

        if done:
            break

    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)
    rewards.append(total_reward)
    epsilon_values.append(epsilon)
    successes.append(1 if total_reward > 0 else 0)

batch_size = 100
avg_rewards = [np.mean(rewards[i:i + batch_size]) for i in range(0, len(rewards), batch_size)]
print('Mean Reward',sum(rewards)/episodes)
print(qtable)

